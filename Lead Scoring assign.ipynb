{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. \n",
    "\n",
    "    The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%. \n",
    "    \n",
    "    Now, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as ‘Hot Leads’. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone.\n",
    "    \n",
    "    As you can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom. In the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.\n",
    "    \n",
    "    X Education has appointed you to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here Importing the warnings and importing the required libraries for Data Analytics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospect ID</th>\n",
       "      <th>Lead Number</th>\n",
       "      <th>Lead Origin</th>\n",
       "      <th>Lead Source</th>\n",
       "      <th>Do Not Email</th>\n",
       "      <th>Do Not Call</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <th>...</th>\n",
       "      <th>Get updates on DM Content</th>\n",
       "      <th>Lead Profile</th>\n",
       "      <th>City</th>\n",
       "      <th>Asymmetrique Activity Index</th>\n",
       "      <th>Asymmetrique Profile Index</th>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "      <th>I agree to pay the amount through cheque</th>\n",
       "      <th>A free copy of Mastering The Interview</th>\n",
       "      <th>Last Notable Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7927b2df-8bba-4d29-b9a2-b6e0beafe620</td>\n",
       "      <td>660737</td>\n",
       "      <td>API</td>\n",
       "      <td>Olark Chat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a272436-5132-4136-86fa-dcc88c88f482</td>\n",
       "      <td>660728</td>\n",
       "      <td>API</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>674</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8cc8c611-a219-4f35-ad23-fdfd2656bd8a</td>\n",
       "      <td>660727</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Potential Lead</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0cc2df48-7cf4-4e39-9de9-19797f9b38cc</td>\n",
       "      <td>660719</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3256f628-e534-4826-9d63-4a8b88782852</td>\n",
       "      <td>660681</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Google</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Prospect ID  Lead Number              Lead Origin  \\\n",
       "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
       "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
       "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
       "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
       "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
       "\n",
       "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
       "0      Olark Chat           No          No          0          0.0   \n",
       "1  Organic Search           No          No          0          5.0   \n",
       "2  Direct Traffic           No          No          1          2.0   \n",
       "3  Direct Traffic           No          No          0          1.0   \n",
       "4          Google           No          No          1          2.0   \n",
       "\n",
       "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
       "0                            0                   0.0  ...   \n",
       "1                          674                   2.5  ...   \n",
       "2                         1532                   2.0  ...   \n",
       "3                          305                   1.0  ...   \n",
       "4                         1428                   1.0  ...   \n",
       "\n",
       "  Get updates on DM Content    Lead Profile    City  \\\n",
       "0                        No          Select  Select   \n",
       "1                        No          Select  Select   \n",
       "2                        No  Potential Lead  Mumbai   \n",
       "3                        No          Select  Mumbai   \n",
       "4                        No          Select  Mumbai   \n",
       "\n",
       "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
       "0                   02.Medium                  02.Medium   \n",
       "1                   02.Medium                  02.Medium   \n",
       "2                   02.Medium                    01.High   \n",
       "3                   02.Medium                    01.High   \n",
       "4                   02.Medium                    01.High   \n",
       "\n",
       "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
       "0                        15.0                       15.0   \n",
       "1                        15.0                       15.0   \n",
       "2                        14.0                       20.0   \n",
       "3                        13.0                       17.0   \n",
       "4                        15.0                       18.0   \n",
       "\n",
       "  I agree to pay the amount through cheque  \\\n",
       "0                                       No   \n",
       "1                                       No   \n",
       "2                                       No   \n",
       "3                                       No   \n",
       "4                                       No   \n",
       "\n",
       "  A free copy of Mastering The Interview Last Notable Activity  \n",
       "0                                     No              Modified  \n",
       "1                                     No          Email Opened  \n",
       "2                                    Yes          Email Opened  \n",
       "3                                     No              Modified  \n",
       "4                                     No              Modified  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads = pd.read_csv(\"../Lead Scoring Assignment/Leads.csv\") # Read the data \n",
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 37)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads.shape #shape of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Prospect ID                                    9240 non-null   object \n",
      " 1   Lead Number                                    9240 non-null   int64  \n",
      " 2   Lead Origin                                    9240 non-null   object \n",
      " 3   Lead Source                                    9204 non-null   object \n",
      " 4   Do Not Email                                   9240 non-null   object \n",
      " 5   Do Not Call                                    9240 non-null   object \n",
      " 6   Converted                                      9240 non-null   int64  \n",
      " 7   TotalVisits                                    9103 non-null   float64\n",
      " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
      " 9   Page Views Per Visit                           9103 non-null   float64\n",
      " 10  Last Activity                                  9137 non-null   object \n",
      " 11  Country                                        6779 non-null   object \n",
      " 12  Specialization                                 7802 non-null   object \n",
      " 13  How did you hear about X Education             7033 non-null   object \n",
      " 14  What is your current occupation                6550 non-null   object \n",
      " 15  What matters most to you in choosing a course  6531 non-null   object \n",
      " 16  Search                                         9240 non-null   object \n",
      " 17  Magazine                                       9240 non-null   object \n",
      " 18  Newspaper Article                              9240 non-null   object \n",
      " 19  X Education Forums                             9240 non-null   object \n",
      " 20  Newspaper                                      9240 non-null   object \n",
      " 21  Digital Advertisement                          9240 non-null   object \n",
      " 22  Through Recommendations                        9240 non-null   object \n",
      " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
      " 24  Tags                                           5887 non-null   object \n",
      " 25  Lead Quality                                   4473 non-null   object \n",
      " 26  Update me on Supply Chain Content              9240 non-null   object \n",
      " 27  Get updates on DM Content                      9240 non-null   object \n",
      " 28  Lead Profile                                   6531 non-null   object \n",
      " 29  City                                           7820 non-null   object \n",
      " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
      " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
      " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
      " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
      " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
      " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
      " 36  Last Notable Activity                          9240 non-null   object \n",
      "dtypes: float64(4), int64(3), object(30)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "leads.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prospect ID                                         0\n",
       "Lead Number                                         0\n",
       "Lead Origin                                         0\n",
       "Lead Source                                        36\n",
       "Do Not Email                                        0\n",
       "Do Not Call                                         0\n",
       "Converted                                           0\n",
       "TotalVisits                                       137\n",
       "Total Time Spent on Website                         0\n",
       "Page Views Per Visit                              137\n",
       "Last Activity                                     103\n",
       "Country                                          2461\n",
       "Specialization                                   1438\n",
       "How did you hear about X Education               2207\n",
       "What is your current occupation                  2690\n",
       "What matters most to you in choosing a course    2709\n",
       "Search                                              0\n",
       "Magazine                                            0\n",
       "Newspaper Article                                   0\n",
       "X Education Forums                                  0\n",
       "Newspaper                                           0\n",
       "Digital Advertisement                               0\n",
       "Through Recommendations                             0\n",
       "Receive More Updates About Our Courses              0\n",
       "Tags                                             3353\n",
       "Lead Quality                                     4767\n",
       "Update me on Supply Chain Content                   0\n",
       "Get updates on DM Content                           0\n",
       "Lead Profile                                     2709\n",
       "City                                             1420\n",
       "Asymmetrique Activity Index                      4218\n",
       "Asymmetrique Profile Index                       4218\n",
       "Asymmetrique Activity Score                      4218\n",
       "Asymmetrique Profile Score                       4218\n",
       "I agree to pay the amount through cheque            0\n",
       "A free copy of Mastering The Interview              0\n",
       "Last Notable Activity                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads.isnull().sum() #null values each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prospect ID                                       0.00\n",
       "Lead Number                                       0.00\n",
       "Lead Origin                                       0.00\n",
       "Lead Source                                       0.39\n",
       "Do Not Email                                      0.00\n",
       "Do Not Call                                       0.00\n",
       "Converted                                         0.00\n",
       "TotalVisits                                       1.48\n",
       "Total Time Spent on Website                       0.00\n",
       "Page Views Per Visit                              1.48\n",
       "Last Activity                                     1.11\n",
       "Country                                          26.63\n",
       "Specialization                                   15.56\n",
       "How did you hear about X Education               23.89\n",
       "What is your current occupation                  29.11\n",
       "What matters most to you in choosing a course    29.32\n",
       "Search                                            0.00\n",
       "Magazine                                          0.00\n",
       "Newspaper Article                                 0.00\n",
       "X Education Forums                                0.00\n",
       "Newspaper                                         0.00\n",
       "Digital Advertisement                             0.00\n",
       "Through Recommendations                           0.00\n",
       "Receive More Updates About Our Courses            0.00\n",
       "Tags                                             36.29\n",
       "Lead Quality                                     51.59\n",
       "Update me on Supply Chain Content                 0.00\n",
       "Get updates on DM Content                         0.00\n",
       "Lead Profile                                     29.32\n",
       "City                                             15.37\n",
       "Asymmetrique Activity Index                      45.65\n",
       "Asymmetrique Profile Index                       45.65\n",
       "Asymmetrique Activity Score                      45.65\n",
       "Asymmetrique Profile Score                       45.65\n",
       "I agree to pay the amount through cheque          0.00\n",
       "A free copy of Mastering The Interview            0.00\n",
       "Last Notable Activity                             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*(leads.isnull().sum())/len(leads.index), 2) # Null Value Percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the distinct values of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lead Origin\n",
       "Landing Page Submission    4886\n",
       "API                        3580\n",
       "Lead Add Form               718\n",
       "Lead Import                  55\n",
       "Quick Add Form                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Lead Origin'\n",
    "leads['Lead Origin'].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lead Source\n",
       "Google               2868\n",
       "Direct Traffic       2543\n",
       "Olark Chat           1755\n",
       "Organic Search       1154\n",
       "Reference             534\n",
       "Welingak Website      142\n",
       "Referral Sites        125\n",
       "Facebook               55\n",
       "bing                    6\n",
       "google                  5\n",
       "Click2call              4\n",
       "Press_Release           2\n",
       "Social Media            2\n",
       "Live Chat               2\n",
       "youtubechannel          1\n",
       "testone                 1\n",
       "Pay per Click Ads       1\n",
       "welearnblog_Home        1\n",
       "WeLearn                 1\n",
       "blog                    1\n",
       "NC_EDM                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Lead Source'\n",
    "\n",
    "leads['Lead Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Do Not Email\n",
       "No     8506\n",
       "Yes     734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Lead Origin'\n",
    "\n",
    "leads['Do Not Email'].value_counts()    # We found out that the variable 'Do Not Email' is a skewed variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Last Activity\n",
       "Email Opened                    3437\n",
       "SMS Sent                        2745\n",
       "Olark Chat Conversation          973\n",
       "Page Visited on Website          640\n",
       "Converted to Lead                428\n",
       "Email Bounced                    326\n",
       "Email Link Clicked               267\n",
       "Form Submitted on Website        116\n",
       "Unreachable                       93\n",
       "Unsubscribed                      61\n",
       "Had a Phone Conversation          30\n",
       "Approached upfront                 9\n",
       "View in browser link Clicked       6\n",
       "Email Received                     2\n",
       "Email Marked Spam                  2\n",
       "Visited Booth in Tradeshow         1\n",
       "Resubscribed to emails             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Last Activity'\n",
    "\n",
    "leads['Last Activity'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "India                   6492\n",
       "United States             69\n",
       "United Arab Emirates      53\n",
       "Singapore                 24\n",
       "Saudi Arabia              21\n",
       "United Kingdom            15\n",
       "Australia                 13\n",
       "Qatar                     10\n",
       "Hong Kong                  7\n",
       "Bahrain                    7\n",
       "Oman                       6\n",
       "France                     6\n",
       "unknown                    5\n",
       "South Africa               4\n",
       "Nigeria                    4\n",
       "Germany                    4\n",
       "Kuwait                     4\n",
       "Canada                     4\n",
       "Sweden                     3\n",
       "China                      2\n",
       "Asia/Pacific Region        2\n",
       "Uganda                     2\n",
       "Bangladesh                 2\n",
       "Italy                      2\n",
       "Belgium                    2\n",
       "Netherlands                2\n",
       "Ghana                      2\n",
       "Philippines                2\n",
       "Russia                     1\n",
       "Switzerland                1\n",
       "Vietnam                    1\n",
       "Denmark                    1\n",
       "Tanzania                   1\n",
       "Liberia                    1\n",
       "Malaysia                   1\n",
       "Kenya                      1\n",
       "Sri Lanka                  1\n",
       "Indonesia                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Country'\n",
    "\n",
    "leads.Country.value_counts()  #  Found out most of the leads are from 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Specialization\n",
       "Select                               1942\n",
       "Finance Management                    976\n",
       "Human Resource Management             848\n",
       "Marketing Management                  838\n",
       "Operations Management                 503\n",
       "Business Administration               403\n",
       "IT Projects Management                366\n",
       "Supply Chain Management               349\n",
       "Banking, Investment And Insurance     338\n",
       "Travel and Tourism                    203\n",
       "Media and Advertising                 203\n",
       "International Business                178\n",
       "Healthcare Management                 159\n",
       "Hospitality Management                114\n",
       "E-COMMERCE                            112\n",
       "Retail Management                     100\n",
       "Rural and Agribusiness                 73\n",
       "E-Business                             57\n",
       "Services Excellence                    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'Specialization'\n",
    "\n",
    "leads['Specialization'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How did you hear about X Education\n",
       "Select                   5043\n",
       "Online Search             808\n",
       "Word Of Mouth             348\n",
       "Student of SomeSchool     310\n",
       "Other                     186\n",
       "Multiple Sources          152\n",
       "Advertisements             70\n",
       "Social Media               67\n",
       "Email                      26\n",
       "SMS                        23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'How did you hear about X Education'\n",
    "\n",
    "leads['How did you hear about X Education'].value_counts() # As most of the cells are not assigned, we should do some imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "What is your current occupation\n",
       "Unemployed              5600\n",
       "Working Professional     706\n",
       "Student                  210\n",
       "Other                     16\n",
       "Housewife                 10\n",
       "Businessman                8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values for 'How did you hear about X Education'\n",
    "\n",
    "leads['What is your current occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Do Not Call\n",
       "No     9238\n",
       "Yes       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Do Not Call'].value_counts() # perfectly sqewed column..... we can drop it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "What matters most to you in choosing a course\n",
       "Better Career Prospects      6528\n",
       "Flexibility & Convenience       2\n",
       "Other                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['What matters most to you in choosing a course'].value_counts() # Perfectly sqewed column..... we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Magazine\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads.Magazine.value_counts() # 100% sqewed, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search\n",
       "No     9226\n",
       "Yes      14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads.Search.value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Get updates on DM Content\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Get updates on DM Content'].value_counts() # 100% sqewed, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Newspaper Article\n",
       "No     9238\n",
       "Yes       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Newspaper Article'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X Education Forums\n",
       "No     9239\n",
       "Yes       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['X Education Forums'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Newspaper\n",
       "No     9239\n",
       "Yes       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Newspaper'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital Advertisement\n",
       "No     9236\n",
       "Yes       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Digital Advertisement'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Through Recommendations\n",
       "No     9233\n",
       "Yes       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Through Recommendations'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Receive More Updates About Our Courses\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Receive More Updates About Our Courses'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Update me on Supply Chain Content\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Update me on Supply Chain Content'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Get updates on DM Content\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Get updates on DM Content'].value_counts() # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lead Profile\n",
       "Select                         4146\n",
       "Potential Lead                 1613\n",
       "Other Leads                     487\n",
       "Student of SomeSchool           241\n",
       "Lateral Student                  24\n",
       "Dual Specialization Student      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Lead Profile'].value_counts() # We see 'select' is occupying most of the columns, so there is need to some imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asymmetrique Activity Index\n",
       "02.Medium    3839\n",
       "01.High       821\n",
       "03.Low        362\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Asymmetrique Activity Index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asymmetrique Profile Index\n",
       "02.Medium    2788\n",
       "01.High      2203\n",
       "03.Low         31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Asymmetrique Profile Index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asymmetrique Activity Score\n",
       "14.0    1771\n",
       "15.0    1293\n",
       "13.0     775\n",
       "16.0     467\n",
       "17.0     349\n",
       "12.0     196\n",
       "11.0      95\n",
       "10.0      57\n",
       "9.0        9\n",
       "18.0       5\n",
       "8.0        4\n",
       "7.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Asymmetrique Activity Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asymmetrique Profile Score\n",
       "15.0    1759\n",
       "18.0    1071\n",
       "16.0     599\n",
       "17.0     579\n",
       "20.0     308\n",
       "19.0     245\n",
       "14.0     226\n",
       "13.0     204\n",
       "12.0      22\n",
       "11.0       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['Asymmetrique Profile Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I agree to pay the amount through cheque\n",
       "No    9240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads['I agree to pay the amount through cheque'].value_counts()  # Sqewed column, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prospect ID', 'Lead Number', 'Lead Origin', 'Lead Source',\n",
       "       'Do Not Email', 'Do Not Call', 'Converted', 'TotalVisits',\n",
       "       'Total Time Spent on Website', 'Page Views Per Visit', 'Last Activity',\n",
       "       'Country', 'Specialization', 'How did you hear about X Education',\n",
       "       'What is your current occupation',\n",
       "       'What matters most to you in choosing a course', 'Search', 'Magazine',\n",
       "       'Newspaper Article', 'X Education Forums', 'Newspaper',\n",
       "       'Digital Advertisement', 'Through Recommendations',\n",
       "       'Receive More Updates About Our Courses', 'Tags', 'Lead Quality',\n",
       "       'Update me on Supply Chain Content', 'Get updates on DM Content',\n",
       "       'Lead Profile', 'City', 'Asymmetrique Activity Index',\n",
       "       'Asymmetrique Profile Index', 'Asymmetrique Activity Score',\n",
       "       'Asymmetrique Profile Score',\n",
       "       'I agree to pay the amount through cheque',\n",
       "       'A free copy of Mastering The Interview', 'Last Notable Activity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads.columns # Let's see the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Inference:`**\n",
    "    1. As many columns has 99 percent same option (Perfectly Sqewed), Those variables won't have any effect on model bulding. Therefore we better drop those columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns which are squewed... \n",
    "\n",
    "leads = leads.drop(['Do Not Call', 'What matters most to you in choosing a course', 'Search', 'Magazine',\n",
    "       'Newspaper Article', 'X Education Forums', 'Newspaper',\n",
    "       'Digital Advertisement', 'Through Recommendations',\n",
    "       'Receive More Updates About Our Courses', 'Update me on Supply Chain Content', 'Get updates on DM Content',\n",
    "       'I agree to pay the amount through cheque'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tags\n",
       "Will revert after reading the email                  2072\n",
       "Ringing                                              1203\n",
       "Interested in other courses                           513\n",
       "Already a student                                     465\n",
       "Closed by Horizzon                                    358\n",
       "switched off                                          240\n",
       "Busy                                                  186\n",
       "Lost to EINS                                          175\n",
       "Not doing further education                           145\n",
       "Interested  in full time MBA                          117\n",
       "Graduation in progress                                111\n",
       "invalid number                                         83\n",
       "Diploma holder (Not Eligible)                          63\n",
       "wrong number given                                     47\n",
       "opp hangup                                             33\n",
       "number not provided                                    27\n",
       "in touch with EINS                                     12\n",
       "Lost to Others                                          7\n",
       "Still Thinking                                          6\n",
       "Want to take admission but has financial problems       6\n",
       "In confusion whether part time or DLP                   5\n",
       "Interested in Next batch                                5\n",
       "Lateral student                                         3\n",
       "Shall take in the next coming month                     2\n",
       "University not recognized                               2\n",
       "Recognition issue (DEC approval)                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's See the distinct values for 'Tags'\n",
    "\n",
    "leads['Tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's See the distinct values for 'A free copy of Mastering The Interview'\n",
    "leads['A free copy of Mastering The Interview'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's See the distinct values for 'Lead Quality'\n",
    "\n",
    "leads['Lead Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's See the distinct values for 'Lead Profile'\n",
    "\n",
    "leads['Lead Profile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's See the distinct values for 'Last Notable Activity'\n",
    "\n",
    "leads['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('Prospect ID', 1) # Drop 'Prospect ID' as it is of less use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_perc = round(leads.isnull().mean()*100,2)\n",
    "null_perc   \n",
    "\n",
    "# The null percentage of columns tells us which are the columns to drop immediatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the columns with null percentage greater than 45% and drop them immediatly,\n",
    "# as high null value percentage won't help our final model. \n",
    "\n",
    "null_perc[null_perc > 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with high null percentages\n",
    "\n",
    "leads = leads.drop(['Lead Quality','Asymmetrique Activity Index', 'Asymmetrique Profile Index',\n",
    "       'Asymmetrique Activity Score', 'Asymmetrique Profile Score'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Do Not Email'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop(['Do Not Email'], axis = 1)  # Drop the column as it is 92% sqewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'].value_counts(normalize = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leads['Lead Source'].value_counts() # value counts of 'Lead Source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'] = leads['Lead Source'].fillna(leads['Lead Source'].mode()[0])\n",
    "\n",
    "# Fill the NAN cells with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'].value_counts() # It is clearly seen that all NAN cells are replaced with mode. i.e., Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw the number of distinct values is high in number, So we shall have to reduce them for better analysis.\n",
    "# We shall retain the names of values with high percentages and put all the low percentage values as Others\n",
    "\n",
    "def Change_Lead_Source_col(x):\n",
    "    if x == 'google':\n",
    "        return 'Google'\n",
    "    elif x == 'Google':\n",
    "        return 'Google'\n",
    "    elif x == 'Direct Traffic':\n",
    "        return 'Direct Traffic'\n",
    "    elif x == 'Olark Chat':\n",
    "        return 'Olark Chat'\n",
    "    elif x == 'Organic Search':\n",
    "        return 'Organic Search'\n",
    "    else : \n",
    "        return 'Others'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'] = leads['Lead Source'].apply(Change_Lead_Source_col) # Lets Apply the modifications as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'].value_counts() # Modified value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Source'].value_counts(normalize = True) # Modified values in percentrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.isnull().sum() # Lets impute the null values of other varibles too in the same way we did it above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Activity'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw the number of distinct values is high in number, So we shall have to reduce them for better analysis.\n",
    "# We shall retain the names of values with high percentages and put all the low percentage values as Others\n",
    "\n",
    "def Change_Last_Activity(x):\n",
    "    if x == 'Email Opened':\n",
    "        return 'Email Opened'\n",
    "    elif x == 'SMS Sent':\n",
    "        return 'SMS Sent'\n",
    "    elif x == 'Olark Chat Conversation':\n",
    "        return 'Olark Chat Conversation'\n",
    "    else : \n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAN cells with mode.\n",
    "leads['Last Activity'] = leads['Last Activity'].fillna(leads['Last Activity'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Activity'] = leads['Last Activity'].apply(Change_Last_Activity) # Apply the modifications as mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Activity'].value_counts(normalize = True)  # Check the modified percentage Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAN cells with mode.\n",
    "leads['Page Views Per Visit'] = leads['Page Views Per Visit'].fillna(leads['Page Views Per Visit'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill the NAN cells with mode.\n",
    "leads['TotalVisits'] = leads['TotalVisits'].fillna(leads['TotalVisits'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(leads.isnull().mean()*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Country.value_counts(normalize = True) # It shows the columns country is skewed and\n",
    "                             # we can actually drop it or make some necessary modifications after treating Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Country.isnull().mean() # As the null values are high in percentage, we better assign them to mode of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Country =leads.Country.fillna(leads.Country.mode()[0]) # Filled Nan with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of distinct values is high in number, So we shall have to reduce them for better analysis.\n",
    "# We shall retain the names of values with high percentages and put all the low percentage values as Others\n",
    "\n",
    "\n",
    "def Change_Country(x):\n",
    "    if x == 'India':\n",
    "        return 'India'\n",
    "    else : \n",
    "        return 'Foreign'\n",
    "\n",
    "#Apply modication made as above mentioned    \n",
    "leads.Country = leads.Country.apply(Change_Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Country.value_counts(normalize = True) # It shows the column is highly sqewed, therefore we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('Country', 1) # Drop the column 'Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(leads.isnull().mean()*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Specialization.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Specialization.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1942+1438)/9240    # Null values are highly overall is about 36.5 percent which is very high in number, therefore drop column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('Specialization', 1) # drop the column 'Specialization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['How did you hear about X Education'].value_counts() # here the 'Select' is almost 50 percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['How did you hear about X Education'].isnull().sum() # The null values and select accounts to around 75% of cells,\n",
    "# Therefore we drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('How did you hear about X Education', 1) # Drop the column 'How did you hear about X Education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leads['What is your current occupation'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['What is your current occupation'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAN cells with mode and see the fresh value counts.\n",
    "leads['What is your current occupation'].fillna('Unemployed', inplace = True)\n",
    "leads['What is your current occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['What is your current occupation'].value_counts(normalize = True)\n",
    "# The column is 90% sqewed, therefore we better drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('What is your current occupation', 1) # Drop the column the 'What is your current occupation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Tags.value_counts()   # Un_modified value counts of Tags column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Tags.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAN cells with mode.\n",
    "leads.Tags = leads.Tags.fillna(leads.Tags.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw the number of distinct values is high in number, So we shall have to reduce them for better analysis.\n",
    "# We shall retain the names of values with high percentages and put all the low percentage values as Others\n",
    "\n",
    "\n",
    "def Change_Tags(x):\n",
    "    if x == 'Will revert after reading the email':\n",
    "        return 'Will revert after reading the email'\n",
    "    elif x == 'Ringing':\n",
    "        return 'Ringing'\n",
    "    elif x == 'Already a student':\n",
    "        return 'Already a student'\n",
    "    else: \n",
    "        return 'Other Reasons'\n",
    "\n",
    "#Apply the modifications made above\n",
    "leads.Tags = leads.Tags.apply(Change_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the modified value counts\n",
    "leads.Tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Profile'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Profile'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAN cells with mode.\n",
    "leads['Lead Profile'].fillna('Select', inplace =  True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the column accordingly\n",
    "\n",
    "def Change_Lead_Profile(x):\n",
    "    if x == 'Select':\n",
    "        return 'Other Leads'\n",
    "    elif x == 'Potential Lead':\n",
    "        return 'Potential Lead'\n",
    "    elif x == 'Other Leads':\n",
    "        return 'Other Leads'\n",
    "    else: \n",
    "        return 'diploma_dual_n_SomeSchool_lead'\n",
    "\n",
    "# Apply the modifications\n",
    "leads['Lead Profile'] = leads['Lead Profile'].apply(Change_Lead_Profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Profile'].value_counts(normalize = True) # Checked the percentage value counts and decided not to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.City.value_counts(normalize = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.City.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.City.fillna('Other Cities', inplace = True) # As we don't know the which city is the Nan cells belong to,\n",
    "                                                  # We better replace them as Other cities\n",
    "leads.City.value_counts(normalize = True)     # Checked the percentage value counts and clearly it is non-sqewed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leads.City.value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the modifications to city column accordingly \n",
    "\n",
    "def Change_City(x):\n",
    "    if x == 'Mumbai':\n",
    "        return 'Mumbai'\n",
    "    elif x == 'Thane & Outskirts':\n",
    "        return 'Other Cities of Maharashtra'\n",
    "    elif x == 'Other Cities of Maharashtra':\n",
    "        return 'Other Cities of Maharashtra'\n",
    "    else: \n",
    "        return 'Other Cities'\n",
    "\n",
    "# Aplly the changes to city column.   \n",
    "leads['City'] = leads['City'].apply(Change_City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the value counts after modifications\n",
    "leads.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['A free copy of Mastering The Interview'].value_counts() # we can apply binary mapping to this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the changes to be made to 'Last Notable Activity' column and apply the changes\n",
    "def Change_Last_Notable_Activity(x):\n",
    "    if x == 'Modified':\n",
    "        return 'Modified'\n",
    "    elif x == 'Email Opened':\n",
    "        return 'Email Opened'\n",
    "    elif x == 'SMS Sent':\n",
    "        return 'SMS Sent'\n",
    "    else: \n",
    "        return 'Other_Activity'\n",
    "\n",
    "leads['Last Notable Activity'] = leads['Last Notable Activity'].apply(Change_Last_Notable_Activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Notable Activity'].value_counts() # Modified value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.Converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'Yes': 1, \"No\": 0})\n",
    "\n",
    "# Applying the function to the column\n",
    "leads[['A free copy of Mastering The Interview']] = leads[['A free copy of Mastering The Interview']].apply(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop('Lead Number', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.columns # Columns remaining after droping highly sqewed columns, high % null columns and not required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy variable for some of the categorical variables and dropping the first one.\n",
    "dummy1 = pd.get_dummies(leads[['Lead Origin', 'Lead Source', 'Last Activity', 'Tags', 'Lead Profile', 'City',\n",
    "                               'Last Notable Activity']], drop_first=True)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "leads = pd.concat([leads, dummy1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head() # after concat we see 33 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the categorical columns after creating dummines\n",
    "leads = leads.drop(['Lead Origin', 'Lead Source', 'Last Activity', 'Tags', 'Lead Profile', 'City',\n",
    "                               'Last Notable Activity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(leads.corr(),annot = True , cmap = 'RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "   1. The **`(last Activity_SMS sent and Last Notable Activity_SMS sent)`** and **`Lead Source_Others and Lead Origin_Lead add form`** are having the highest correlation. So that we can drop any one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop(['Last Activity_SMS Sent', 'Lead Source_Others'],1) # Drop the highly corellated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Let's start by splitting our data into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split & Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the train_test_split and StandardScaler from scikit Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variables to X\n",
    "X = leads.drop('Converted', axis=1) \n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = leads['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the object.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create a var-list to fit, we shall only take numeric variables to fit, \n",
    "# since the scalling wont show any effect on categorical variables as they are already in between 0 and 1\n",
    "\n",
    "X_train[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_train[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking the converted Rate\n",
    "converted = (sum(leads['Converted'])/len(leads['Converted'].index))*100\n",
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(leads.corr(),annot = True , cmap = 'RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels for better analytics\n",
    "import statsmodels.api as sm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model using GLM (Generalized linear model)  and by using binomial family of distribution curves\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building through RFE (Recursive feature elimination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required scikit learn libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Instantiate LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# assign number of variable for automatic selection\n",
    "rfe = RFE(logreg, 15)   \n",
    "\n",
    "# fit the rfe model\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at which are the variable with high significance and which are low\n",
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see all the column names and their corresponding significance and ranking\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a list with columns of highest significance\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with low significance\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a constant\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "\n",
    "# Create a Logestic regression model using GLM\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "\n",
    "#Fit the model\n",
    "res = logm2.fit()\n",
    "\n",
    "# view the summary\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: \n",
    "   1. Clearly **`Lead Origin_Landing Page Submission`** is exceeding the permissible p_value, we shall have to drop it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column with high p_value and assign the remaining to the same\n",
    "col = col.drop('Lead Origin_Landing Page Submission', 1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables\n",
    "\n",
    "# Add a constant\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "\n",
    "# Create a Logestic regression model using GLM\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "\n",
    "#Fit the model\n",
    "res = logm3.fit()\n",
    "\n",
    "# view the summary\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column with high p_value and assign the remaining to the same\n",
    "col = col.drop('City_Other Cities',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a constant\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "\n",
    "# Create a Logestic regression model using GLM\n",
    "logm4 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "\n",
    "#Fit the model\n",
    "res = logm4.fit()\n",
    "\n",
    "# view the summary\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column with high p_value and assign the remaining to the same\n",
    "col = col.drop('Tags_Ringing',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables\n",
    "# Add a constant\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "\n",
    "# Create a Logestic regression model using GLM\n",
    "logm5 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "\n",
    "#Fit the model\n",
    "res = logm5.fit()\n",
    "\n",
    "# view the summary\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res.predict(X_train_sm).values.reshape(-1) # Reshape it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the values in array to a data_frame and name them\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "\n",
    "# Assign an ID to the training set\n",
    "y_train_pred_final['StudID'] = y_train.index\n",
    "\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume a rough treashold value, say 0.5 and predict the lead conversion \n",
    "y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics # import metrics from sciket learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted            Non_Converted   Converted\n",
    "# Actual\n",
    "# not_Converted        3667             335\n",
    "# Converted            486              1980  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting converted when student had not got converted\n",
    "print(FP/ float(TN+FP)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ROC curve demonstrates several things:\n",
    "\n",
    "- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
    "- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal cutoff probability is that prob where we get balanced sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: \n",
    "   1. With the help of above plot, we can select a threshold probability value by having a trade_off between accuracy, Sensitivity and Specificity. \n",
    "   2. It clearly says, we can take Threshold probability **`x = 0.3`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.3 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's again print the confusion matric with the final predicted lead conversion by the model (X=0.3)\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the confusion matrix again\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision\n",
    "TP / TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[0,1]+confusion[1,1]) # CEO expecting atleast 80%, but we got around 85 %. Therefore the model is satisfying the demands of CEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall\n",
    "TP / TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: \n",
    "   1. By looking at the Precision and Recall Tradeoff, we can go with a probability threshold value as **`x = 0.41`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take only the final columns after treating them for high P_value and High VIF's\n",
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constant\n",
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the predicticed probalilities in the test set\n",
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['StudID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.41 else 0)\n",
    "# Here we took x= 0.41, which is the trade off probability value from precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head() # Head of the test set showing actual converted and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['Lead Score'] = round(y_pred_final['Converted_Prob']*100,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hot_Cold_mapping(x):\n",
    "    return x.map({1:'Hot', 0:'Cold'})\n",
    "\n",
    "y_pred_final[['Target']] = y_pred_final[['final_predicted']].apply(Hot_Cold_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head() # Head of the test set showing actual converted and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['Converted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "   1. The Accuracy Scores, sensitivity and specificity of Training and test sets is almost equal. We can conclude that, the model that was built is good to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP/(TP + FP) # CEO expecting atleast 80%, but we got around 83 % precision. Therefore the model is satisfying the demands of CEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "   - CEO expecting atleast 80%, but we got around 83 % precision. Therefore the model is satisfying the demands of CEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(leads.corr(),annot = True , cmap = 'RdYlGn')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
